{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a9a8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05ba78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/WSN-DS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a396b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Is_CH</th>\n",
       "      <th>who CH</th>\n",
       "      <th>Dist_To_CH</th>\n",
       "      <th>ADV_S</th>\n",
       "      <th>ADV_R</th>\n",
       "      <th>JOIN_S</th>\n",
       "      <th>JOIN_R</th>\n",
       "      <th>SCH_S</th>\n",
       "      <th>SCH_R</th>\n",
       "      <th>Rank</th>\n",
       "      <th>DATA_S</th>\n",
       "      <th>DATA_R</th>\n",
       "      <th>Data_Sent_To_BS</th>\n",
       "      <th>dist_CH_To_BS</th>\n",
       "      <th>send_code</th>\n",
       "      <th>Expaned Energy</th>\n",
       "      <th>Attack type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101000</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>101000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>48</td>\n",
       "      <td>130.08535</td>\n",
       "      <td>0</td>\n",
       "      <td>2.46940</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101001</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>101044</td>\n",
       "      <td>75.32345</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06957</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101002</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>101010</td>\n",
       "      <td>46.95453</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06898</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101003</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>101044</td>\n",
       "      <td>64.85231</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06673</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101004</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>101010</td>\n",
       "      <td>4.83341</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06534</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   Time   Is_CH   who CH   Dist_To_CH   ADV_S   ADV_R   JOIN_S  \\\n",
       "0  101000     50       1   101000      0.00000       1       0        0   \n",
       "1  101001     50       0   101044     75.32345       0       4        1   \n",
       "2  101002     50       0   101010     46.95453       0       4        1   \n",
       "3  101003     50       0   101044     64.85231       0       4        1   \n",
       "4  101004     50       0   101010      4.83341       0       4        1   \n",
       "\n",
       "    JOIN_R   SCH_S   SCH_R  Rank   DATA_S   DATA_R   Data_Sent_To_BS  \\\n",
       "0       25       1       0     0        0     1200                48   \n",
       "1        0       0       1     2       38        0                 0   \n",
       "2        0       0       1    19       41        0                 0   \n",
       "3        0       0       1    16       38        0                 0   \n",
       "4        0       0       1    25       41        0                 0   \n",
       "\n",
       "    dist_CH_To_BS   send_code   Expaned Energy Attack type  \n",
       "0       130.08535            0         2.46940      Normal  \n",
       "1         0.00000            4         0.06957      Normal  \n",
       "2         0.00000            3         0.06898      Normal  \n",
       "3         0.00000            4         0.06673      Normal  \n",
       "4         0.00000            3         0.06534      Normal  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1275f42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Is_CH</th>\n",
       "      <th>who CH</th>\n",
       "      <th>Dist_To_CH</th>\n",
       "      <th>ADV_S</th>\n",
       "      <th>ADV_R</th>\n",
       "      <th>JOIN_S</th>\n",
       "      <th>JOIN_R</th>\n",
       "      <th>SCH_S</th>\n",
       "      <th>SCH_R</th>\n",
       "      <th>Rank</th>\n",
       "      <th>DATA_S</th>\n",
       "      <th>DATA_R</th>\n",
       "      <th>Data_Sent_To_BS</th>\n",
       "      <th>dist_CH_To_BS</th>\n",
       "      <th>send_code</th>\n",
       "      <th>Expaned Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.746610e+05</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>3.746610e+05</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "      <td>374661.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.749693e+05</td>\n",
       "      <td>1064.748712</td>\n",
       "      <td>0.115766</td>\n",
       "      <td>2.749804e+05</td>\n",
       "      <td>22.599380</td>\n",
       "      <td>0.267698</td>\n",
       "      <td>6.940562</td>\n",
       "      <td>0.779905</td>\n",
       "      <td>0.737493</td>\n",
       "      <td>0.288984</td>\n",
       "      <td>0.747452</td>\n",
       "      <td>9.687104</td>\n",
       "      <td>44.857925</td>\n",
       "      <td>73.890045</td>\n",
       "      <td>4.569448</td>\n",
       "      <td>22.562735</td>\n",
       "      <td>2.497957</td>\n",
       "      <td>0.305661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.898986e+05</td>\n",
       "      <td>899.646164</td>\n",
       "      <td>0.319945</td>\n",
       "      <td>3.899112e+05</td>\n",
       "      <td>21.955794</td>\n",
       "      <td>2.061148</td>\n",
       "      <td>7.044319</td>\n",
       "      <td>0.414311</td>\n",
       "      <td>4.691498</td>\n",
       "      <td>2.754746</td>\n",
       "      <td>0.434475</td>\n",
       "      <td>14.681901</td>\n",
       "      <td>42.574464</td>\n",
       "      <td>230.246335</td>\n",
       "      <td>19.679155</td>\n",
       "      <td>50.261604</td>\n",
       "      <td>2.407337</td>\n",
       "      <td>0.669462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.010000e+05</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.010000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.070930e+05</td>\n",
       "      <td>353.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.070960e+05</td>\n",
       "      <td>4.735440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.160710e+05</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.160720e+05</td>\n",
       "      <td>18.372610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.097970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.150720e+05</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.150730e+05</td>\n",
       "      <td>33.776000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.217760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.402096e+06</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.402100e+06</td>\n",
       "      <td>214.274620</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>1496.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>201.934940</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>45.093940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           Time          Is_CH        who CH  \\\n",
       "count  3.746610e+05  374661.000000  374661.000000  3.746610e+05   \n",
       "mean   2.749693e+05    1064.748712       0.115766  2.749804e+05   \n",
       "std    3.898986e+05     899.646164       0.319945  3.899112e+05   \n",
       "min    1.010000e+05      50.000000       0.000000  1.010000e+05   \n",
       "25%    1.070930e+05     353.000000       0.000000  1.070960e+05   \n",
       "50%    1.160710e+05     803.000000       0.000000  1.160720e+05   \n",
       "75%    2.150720e+05    1503.000000       0.000000  2.150730e+05   \n",
       "max    3.402096e+06    3600.000000       1.000000  3.402100e+06   \n",
       "\n",
       "          Dist_To_CH          ADV_S          ADV_R         JOIN_S  \\\n",
       "count  374661.000000  374661.000000  374661.000000  374661.000000   \n",
       "mean       22.599380       0.267698       6.940562       0.779905   \n",
       "std        21.955794       2.061148       7.044319       0.414311   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         4.735440       0.000000       3.000000       1.000000   \n",
       "50%        18.372610       0.000000       5.000000       1.000000   \n",
       "75%        33.776000       0.000000       7.000000       1.000000   \n",
       "max       214.274620      97.000000     117.000000       1.000000   \n",
       "\n",
       "              JOIN_R          SCH_S          SCH_R           Rank  \\\n",
       "count  374661.000000  374661.000000  374661.000000  374661.000000   \n",
       "mean        0.737493       0.288984       0.747452       9.687104   \n",
       "std         4.691498       2.754746       0.434475      14.681901   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       1.000000   \n",
       "50%         0.000000       0.000000       1.000000       3.000000   \n",
       "75%         0.000000       0.000000       1.000000      13.000000   \n",
       "max       124.000000      99.000000       1.000000      99.000000   \n",
       "\n",
       "              DATA_S         DATA_R   Data_Sent_To_BS   dist_CH_To_BS  \\\n",
       "count  374661.000000  374661.000000     374661.000000   374661.000000   \n",
       "mean       44.857925      73.890045          4.569448       22.562735   \n",
       "std        42.574464     230.246335         19.679155       50.261604   \n",
       "min         0.000000       0.000000          0.000000        0.000000   \n",
       "25%        13.000000       0.000000          0.000000        0.000000   \n",
       "50%        35.000000       0.000000          0.000000        0.000000   \n",
       "75%        62.000000       0.000000          0.000000        0.000000   \n",
       "max       241.000000    1496.000000        241.000000      201.934940   \n",
       "\n",
       "          send_code   Expaned Energy  \n",
       "count  374661.000000   374661.000000  \n",
       "mean        2.497957        0.305661  \n",
       "std         2.407337        0.669462  \n",
       "min         0.000000        0.000000  \n",
       "25%         1.000000        0.056150  \n",
       "50%         2.000000        0.097970  \n",
       "75%         4.000000        0.217760  \n",
       "max        15.000000       45.093940  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4643900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 374661 entries, 0 to 374660\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0    id               374661 non-null  int64  \n",
      " 1    Time             374661 non-null  int64  \n",
      " 2    Is_CH            374661 non-null  int64  \n",
      " 3    who CH           374661 non-null  int64  \n",
      " 4    Dist_To_CH       374661 non-null  float64\n",
      " 5    ADV_S            374661 non-null  int64  \n",
      " 6    ADV_R            374661 non-null  int64  \n",
      " 7    JOIN_S           374661 non-null  int64  \n",
      " 8    JOIN_R           374661 non-null  int64  \n",
      " 9    SCH_S            374661 non-null  int64  \n",
      " 10   SCH_R            374661 non-null  int64  \n",
      " 11  Rank              374661 non-null  int64  \n",
      " 12   DATA_S           374661 non-null  int64  \n",
      " 13   DATA_R           374661 non-null  int64  \n",
      " 14   Data_Sent_To_BS  374661 non-null  int64  \n",
      " 15   dist_CH_To_BS    374661 non-null  float64\n",
      " 16   send_code        374661 non-null  int64  \n",
      " 17  Expaned Energy    374661 non-null  float64\n",
      " 18  Attack type       374661 non-null  object \n",
      "dtypes: float64(3), int64(15), object(1)\n",
      "memory usage: 54.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "439bf2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " id                 0\n",
       " Time               0\n",
       " Is_CH              0\n",
       " who CH             0\n",
       " Dist_To_CH         0\n",
       " ADV_S              0\n",
       " ADV_R              0\n",
       " JOIN_S             0\n",
       " JOIN_R             0\n",
       " SCH_S              0\n",
       " SCH_R              0\n",
       "Rank                0\n",
       " DATA_S             0\n",
       " DATA_R             0\n",
       " Data_Sent_To_BS    0\n",
       " dist_CH_To_BS      0\n",
       " send_code          0\n",
       "Expaned Energy      0\n",
       "Attack type         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1444b",
   "metadata": {},
   "source": [
    "### Checking class distribution of the 'Attack type' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd969b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Attack type'].value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution of Attack Types')\n",
    "plt.xlabel('Attack Type')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9694aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack type\n",
      "Normal       340066\n",
      "Grayhole      14596\n",
      "Blackhole     10049\n",
      "TDMA           6638\n",
      "Flooding       3312\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "attack_type_counts = df['Attack type'].value_counts()\n",
    "print(attack_type_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08e75b",
   "metadata": {},
   "source": [
    "## Ensemble Learning Model with Weighted Class Loss\n",
    "Train an ensemble model (Random Forest) on the WSN-DS dataset. To address class imbalance, will use class weights in the loss function so that minority classes are not ignored during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "588cc544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Encode categorical variables, split features/labels, and train/test split\n",
    "\n",
    "# Encode 'Attack type' as target\n",
    "le = LabelEncoder()\n",
    "df['Attack type Encoded'] = le.fit_transform(df['Attack type'])\n",
    "\n",
    "# Select features (drop non-feature columns)\n",
    "X = df.drop(['Attack type', 'Attack type Encoded'], axis=1, errors='ignore')\n",
    "y = df['Attack type Encoded']\n",
    "\n",
    "# If there are any non-numeric columns, encode them\n",
    "def encode_non_numeric(X):\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':\n",
    "            X[col] = LabelEncoder().fit_transform(X[col])\n",
    "    return X\n",
    "X = encode_non_numeric(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8be4dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(7.456847866650081), 1: np.float64(22.62098113207547), 2: np.float64(5.133647340926608), 3: np.float64(0.22034611030244217), 4: np.float64(11.28919020715631)}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights for the ensemble model\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {i : w for i, w in enumerate(class_weights)}\n",
    "print('Class weights:', class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71dbaa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an ensemble model (RandomForestClassifier) with class weights\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=class_weight_dict, n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21c8270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9971441154097661\n",
      "Confusion Matrix:\n",
      " [[ 2004     0     6     0     0]\n",
      " [    0   655     0     7     0]\n",
      " [   16     0  2885    18     0]\n",
      " [    2    43    23 67939     7]\n",
      " [    0     0     0    92  1236]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Blackhole       0.99      1.00      0.99      2010\n",
      "    Flooding       0.94      0.99      0.96       662\n",
      "    Grayhole       0.99      0.99      0.99      2919\n",
      "      Normal       1.00      1.00      1.00     68014\n",
      "        TDMA       0.99      0.93      0.96      1328\n",
      "\n",
      "    accuracy                           1.00     74933\n",
      "   macro avg       0.98      0.98      0.98     74933\n",
      "weighted avg       1.00      1.00      1.00     74933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble model\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a557483d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack Type</th>\n",
       "      <th>TPR (Recall)</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blackhole</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.998211</td>\n",
       "      <td>0.999936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flooding</td>\n",
       "      <td>0.997886</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.987157</td>\n",
       "      <td>0.999867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grayhole</td>\n",
       "      <td>0.997671</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.998012</td>\n",
       "      <td>0.999832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.996589</td>\n",
       "      <td>0.999653</td>\n",
       "      <td>0.999477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TDMA</td>\n",
       "      <td>0.985990</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.014010</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.998474</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attack Type  TPR (Recall)       FPR       FNR       TNR  Precision  Accuracy\n",
       "0   Blackhole      0.999403  0.000049  0.000597  0.999951   0.998211  0.999936\n",
       "1    Flooding      0.997886  0.000116  0.002114  0.999884   0.987157  0.999867\n",
       "2    Grayhole      0.997671  0.000081  0.002329  0.999919   0.998012  0.999832\n",
       "3      Normal      0.999771  0.003411  0.000229  0.996589   0.999653  0.999477\n",
       "4        TDMA      0.985990  0.000027  0.014010  0.999973   0.998474  0.999725"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the entire dataset\n",
    "full_pred = rf.predict(X)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y, full_pred)\n",
    "classes = le.classes_\n",
    "\n",
    "# Initialize metrics storage\n",
    "results = []\n",
    "for i, class_name in enumerate(classes):\n",
    "    TP = cm[i, i]\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall\n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    Precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    Accuracy = (TP + TN) / cm.sum() if cm.sum() > 0 else 0\n",
    "    results.append({\n",
    "        'Attack Type': class_name,\n",
    "        'TPR (Recall)': TPR,\n",
    "        'FPR': FPR,\n",
    "        'FNR': FNR,\n",
    "        'TNR': TNR,\n",
    "        'Precision': Precision,\n",
    "        'Accuracy': Accuracy\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e46ff",
   "metadata": {},
   "source": [
    "## Ensemble Neural Network with Focal Loss\n",
    "We will train an ensemble of neural networks (bagging) using the focal loss function to address class imbalance. Each neural network will be trained on a bootstrap sample of the data, and their predictions will be averaged for the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "741598e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_true = tf.one_hot(y_true, depth=y_pred.shape[-1])\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        weight = alpha * K.pow(1 - y_pred, gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        loss = K.sum(loss, axis=-1) \n",
    "        return loss\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0ac3333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191us/step\n",
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192us/step\n",
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191us/step\n",
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188us/step\n",
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191us/step\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "n_estimators = 5\n",
    "ensemble_preds = []\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    X_boot, y_boot = resample(X, y, replace=True, random_state=42+i)\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=focal_loss(gamma=2., alpha=.25),\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_boot, y_boot, epochs=15, batch_size=256, class_weight=class_weight_dict, verbose=0)\n",
    "    ensemble_preds.append(model.predict(X))\n",
    "\n",
    "ensemble_pred_proba = np.mean(ensemble_preds, axis=0)\n",
    "ensemble_pred = np.argmax(ensemble_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd640336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack Type</th>\n",
       "      <th>TPR (Recall)</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blackhole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flooding</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grayhole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.961042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907663</td>\n",
       "      <td>0.907663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TDMA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attack Type  TPR (Recall)  FPR  FNR  TNR  Precision  Accuracy\n",
       "0   Blackhole           0.0  0.0  1.0  1.0   0.000000  0.973178\n",
       "1    Flooding           0.0  0.0  1.0  1.0   0.000000  0.991160\n",
       "2    Grayhole           0.0  0.0  1.0  1.0   0.000000  0.961042\n",
       "3      Normal           1.0  1.0  0.0  0.0   0.907663  0.907663\n",
       "4        TDMA           0.0  0.0  1.0  1.0   0.000000  0.982283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack Type</th>\n",
       "      <th>TPR (Recall)</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blackhole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flooding</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grayhole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.961042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907663</td>\n",
       "      <td>0.907663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TDMA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attack Type  TPR (Recall)  FPR  FNR  TNR  Precision  Accuracy\n",
       "0   Blackhole           0.0  0.0  1.0  1.0   0.000000  0.973178\n",
       "1    Flooding           0.0  0.0  1.0  1.0   0.000000  0.991160\n",
       "2    Grayhole           0.0  0.0  1.0  1.0   0.000000  0.961042\n",
       "3      Normal           1.0  1.0  0.0  0.0   0.907663  0.907663\n",
       "4        TDMA           0.0  0.0  1.0  1.0   0.000000  0.982283"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the ensemble neural network with focal loss on the entire dataset\n",
    "cm_ensemble = confusion_matrix(y, ensemble_pred)\n",
    "\n",
    "results_ensemble = []\n",
    "for i, class_name in enumerate(classes):\n",
    "    TP = cm_ensemble[i, i]\n",
    "    FN = cm_ensemble[i, :].sum() - TP\n",
    "    FP = cm_ensemble[:, i].sum() - TP\n",
    "    TN = cm_ensemble.sum() - (TP + FP + FN)\n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall\n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    Precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    Accuracy = (TP + TN) / cm_ensemble.sum() if cm_ensemble.sum() > 0 else 0\n",
    "    results_ensemble.append({\n",
    "        'Attack Type': class_name,\n",
    "        'TPR (Recall)': TPR,\n",
    "        'FPR': FPR,\n",
    "        'FNR': FNR,\n",
    "        'TNR': TNR,\n",
    "        'Precision': Precision,\n",
    "        'Accuracy': Accuracy\n",
    "    })\n",
    "\n",
    "results_ensemble_df = pd.DataFrame(results_ensemble)\n",
    "display(results_ensemble_df)\n",
    "results_ensemble_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8bbd00",
   "metadata": {},
   "source": [
    "## Improved Ensemble Neural Network with Focal Loss\n",
    "- Feature scaling (StandardScaler)\n",
    "- Increased alpha in focal loss to 0.75\n",
    "- Lowered learning rate to 0.0005\n",
    "- Increased epochs to 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44bd1c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63c34c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 0.2432\n",
      "Epoch 2/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.1782\n",
      "Epoch 3/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1769\n",
      "Epoch 4/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.1684\n",
      "Epoch 5/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.1737\n",
      "Epoch 6/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.1738\n",
      "Epoch 7/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1683\n",
      "Epoch 8/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1684\n",
      "Epoch 9/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1713\n",
      "Epoch 10/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.1704\n",
      "Epoch 11/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1702\n",
      "Epoch 12/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.1692\n",
      "Epoch 13/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1690\n",
      "Epoch 14/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1698\n",
      "Epoch 15/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1693\n",
      "Epoch 16/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1708\n",
      "Epoch 17/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1719\n",
      "Epoch 18/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1705\n",
      "Epoch 19/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.1718\n",
      "Epoch 20/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.1694\n",
      "Epoch 21/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1687\n",
      "Epoch 22/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1697\n",
      "Epoch 23/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1695\n",
      "Epoch 24/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1694\n",
      "Epoch 25/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.1680\n",
      "Epoch 26/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1692\n",
      "Epoch 27/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1683\n",
      "Epoch 28/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.1702\n",
      "Epoch 29/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1690\n",
      "Epoch 30/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1695\n",
      "Epoch 31/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1674\n",
      "Epoch 32/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1683\n",
      "Epoch 33/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.1703\n",
      "Epoch 34/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.1704\n",
      "Epoch 35/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1696\n",
      "Epoch 36/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.1722\n",
      "Epoch 37/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.1715\n",
      "Epoch 38/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1677\n",
      "Epoch 39/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1678\n",
      "Epoch 40/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.1713\n",
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203us/step\n",
      "Epoch 1/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.2623\n",
      "Epoch 2/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.1779\n",
      "Epoch 3/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.1750\n",
      "Epoch 4/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1698\n",
      "Epoch 5/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1702\n",
      "Epoch 6/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1677\n",
      "Epoch 7/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.1695\n",
      "Epoch 8/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.1657\n",
      "Epoch 9/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1675\n",
      "Epoch 10/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1672\n",
      "Epoch 11/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1688\n",
      "Epoch 12/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1673\n",
      "Epoch 13/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1694\n",
      "Epoch 14/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.1702\n",
      "Epoch 15/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1698\n",
      "Epoch 16/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.1668\n",
      "Epoch 17/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1664\n",
      "Epoch 18/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.1685\n",
      "Epoch 19/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1675\n",
      "Epoch 20/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1680\n",
      "Epoch 21/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1675\n",
      "Epoch 22/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.1680\n",
      "Epoch 23/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1686\n",
      "Epoch 24/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.1676\n",
      "Epoch 25/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1677\n",
      "Epoch 26/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1677\n",
      "Epoch 27/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1690\n",
      "Epoch 28/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1670\n",
      "Epoch 29/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.1715\n",
      "Epoch 30/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1670\n",
      "Epoch 31/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.1705\n",
      "Epoch 32/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1683\n",
      "Epoch 33/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.1691\n",
      "Epoch 34/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.1659\n",
      "Epoch 35/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1670\n",
      "Epoch 36/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1695\n",
      "Epoch 37/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.1639\n",
      "Epoch 38/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.1654\n",
      "Epoch 39/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.1655\n",
      "Epoch 40/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1653\n",
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197us/step\n",
      "Epoch 1/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8646 - loss: 0.2431\n",
      "Epoch 2/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1797\n",
      "Epoch 3/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1754\n",
      "Epoch 4/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.1776\n",
      "Epoch 5/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1708\n",
      "Epoch 6/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1709\n",
      "Epoch 7/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.1738\n",
      "Epoch 8/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1711\n",
      "Epoch 9/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1690\n",
      "Epoch 10/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.1720\n",
      "Epoch 11/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1698\n",
      "Epoch 12/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.1722\n",
      "Epoch 13/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1711\n",
      "Epoch 14/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.1671\n",
      "Epoch 15/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1701\n",
      "Epoch 16/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.1733\n",
      "Epoch 17/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1712\n",
      "Epoch 18/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.1720\n",
      "Epoch 19/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.1718\n",
      "Epoch 20/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.1729\n",
      "Epoch 21/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1702\n",
      "Epoch 22/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1705\n",
      "Epoch 23/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1688\n",
      "Epoch 24/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1689\n",
      "Epoch 25/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1685\n",
      "Epoch 26/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1705\n",
      "Epoch 27/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.1735\n",
      "Epoch 28/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.1708\n",
      "Epoch 29/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1708\n",
      "Epoch 30/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1696\n",
      "Epoch 31/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.1734\n",
      "Epoch 32/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.1726\n",
      "Epoch 33/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1714\n",
      "Epoch 34/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1699\n",
      "Epoch 35/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1699\n",
      "Epoch 36/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1702\n",
      "Epoch 37/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1705\n",
      "Epoch 38/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1702\n",
      "Epoch 39/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.1692\n",
      "Epoch 40/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.1712\n",
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189us/step\n",
      "Epoch 1/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.2206\n",
      "Epoch 2/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1766\n",
      "Epoch 3/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1726\n",
      "Epoch 4/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.1694\n",
      "Epoch 5/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.1691\n",
      "Epoch 6/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1706\n",
      "Epoch 7/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1686\n",
      "Epoch 8/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1710\n",
      "Epoch 9/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1705\n",
      "Epoch 10/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.1679\n",
      "Epoch 11/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1702\n",
      "Epoch 12/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.1721\n",
      "Epoch 13/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1695\n",
      "Epoch 14/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.1692\n",
      "Epoch 15/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.1717\n",
      "Epoch 16/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.1681\n",
      "Epoch 17/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.1659\n",
      "Epoch 18/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.1663\n",
      "Epoch 19/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.1694\n",
      "Epoch 20/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1706\n",
      "Epoch 21/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.1681\n",
      "Epoch 22/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.1681\n",
      "Epoch 23/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.1682\n",
      "Epoch 24/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1670\n",
      "Epoch 25/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.1685\n",
      "Epoch 26/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.1679\n",
      "Epoch 27/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1678\n",
      "Epoch 28/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.1689\n",
      "Epoch 29/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.1690\n",
      "Epoch 30/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.1665\n",
      "Epoch 31/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.1678\n",
      "Epoch 32/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.1657\n",
      "Epoch 33/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.1679\n",
      "Epoch 34/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.1672\n",
      "Epoch 35/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1691\n",
      "Epoch 36/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.1664\n",
      "Epoch 37/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.1675\n",
      "Epoch 38/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1698\n",
      "Epoch 39/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.1692\n",
      "Epoch 40/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.1678\n",
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190us/step\n",
      "Epoch 1/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.2300\n",
      "Epoch 2/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1771\n",
      "Epoch 3/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1717\n",
      "Epoch 4/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1726\n",
      "Epoch 5/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.1753\n",
      "Epoch 6/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1682\n",
      "Epoch 7/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.1721\n",
      "Epoch 8/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1698\n",
      "Epoch 9/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.1697\n",
      "Epoch 10/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1669\n",
      "Epoch 11/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1694\n",
      "Epoch 12/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1697\n",
      "Epoch 13/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1693\n",
      "Epoch 14/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.1666\n",
      "Epoch 15/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.1695\n",
      "Epoch 16/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1694\n",
      "Epoch 17/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1692\n",
      "Epoch 18/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1696\n",
      "Epoch 19/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1667\n",
      "Epoch 20/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1689\n",
      "Epoch 21/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1702\n",
      "Epoch 22/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.1685\n",
      "Epoch 23/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.1684\n",
      "Epoch 24/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1671\n",
      "Epoch 25/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.1691\n",
      "Epoch 26/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.1672\n",
      "Epoch 27/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1681\n",
      "Epoch 28/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1700\n",
      "Epoch 29/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1669\n",
      "Epoch 30/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.1680\n",
      "Epoch 31/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.1693\n",
      "Epoch 32/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.1710\n",
      "Epoch 33/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9074 - loss: 0.1701\n",
      "Epoch 34/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.1691\n",
      "Epoch 35/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.1670\n",
      "Epoch 36/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.1689\n",
      "Epoch 37/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.1692\n",
      "Epoch 38/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1685\n",
      "Epoch 39/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1682\n",
      "Epoch 40/40\n",
      "\u001b[1m1464/1464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1663\n",
      "\u001b[1m11709/11709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204us/step\n"
     ]
    }
   ],
   "source": [
    "# Improved ensemble neural network training with focal loss and feature scaling\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "n_estimators = 5\n",
    "ensemble_preds = []\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    X_boot, y_boot = resample(X_scaled, y, replace=True, random_state=42+i)\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_scaled.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "                  loss=focal_loss(gamma=2., alpha=0.75),\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_boot, y_boot, epochs=40, batch_size=256, class_weight=class_weight_dict, verbose=1)\n",
    "    ensemble_preds.append(model.predict(X_scaled))\n",
    "\n",
    "ensemble_pred_proba = np.mean(ensemble_preds, axis=0)\n",
    "ensemble_pred = np.argmax(ensemble_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2759177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack Type</th>\n",
       "      <th>TPR (Recall)</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blackhole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flooding</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grayhole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.961042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907663</td>\n",
       "      <td>0.907663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TDMA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attack Type  TPR (Recall)  FPR  FNR  TNR  Precision  Accuracy\n",
       "0   Blackhole           0.0  0.0  1.0  1.0   0.000000  0.973178\n",
       "1    Flooding           0.0  0.0  1.0  1.0   0.000000  0.991160\n",
       "2    Grayhole           0.0  0.0  1.0  1.0   0.000000  0.961042\n",
       "3      Normal           1.0  1.0  0.0  0.0   0.907663  0.907663\n",
       "4        TDMA           0.0  0.0  1.0  1.0   0.000000  0.982283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack Type</th>\n",
       "      <th>TPR (Recall)</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blackhole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flooding</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grayhole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.961042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907663</td>\n",
       "      <td>0.907663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TDMA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attack Type  TPR (Recall)  FPR  FNR  TNR  Precision  Accuracy\n",
       "0   Blackhole           0.0  0.0  1.0  1.0   0.000000  0.973178\n",
       "1    Flooding           0.0  0.0  1.0  1.0   0.000000  0.991160\n",
       "2    Grayhole           0.0  0.0  1.0  1.0   0.000000  0.961042\n",
       "3      Normal           1.0  1.0  0.0  0.0   0.907663  0.907663\n",
       "4        TDMA           0.0  0.0  1.0  1.0   0.000000  0.982283"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_ensemble = confusion_matrix(y, ensemble_pred)\n",
    "\n",
    "results_ensemble = []\n",
    "for i, class_name in enumerate(classes):\n",
    "    TP = cm_ensemble[i, i]\n",
    "    FN = cm_ensemble[i, :].sum() - TP\n",
    "    FP = cm_ensemble[:, i].sum() - TP\n",
    "    TN = cm_ensemble.sum() - (TP + FP + FN)\n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall\n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    Precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    Accuracy = (TP + TN) / cm_ensemble.sum() if cm_ensemble.sum() > 0 else 0\n",
    "    results_ensemble.append({\n",
    "        'Attack Type': class_name,\n",
    "        'TPR (Recall)': TPR,\n",
    "        'FPR': FPR,\n",
    "        'FNR': FNR,\n",
    "        'TNR': TNR,\n",
    "        'Precision': Precision,\n",
    "        'Accuracy': Accuracy\n",
    "    })\n",
    "\n",
    "results_ensemble_df = pd.DataFrame(results_ensemble)\n",
    "display(results_ensemble_df)\n",
    "results_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52ecbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
